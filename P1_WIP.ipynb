{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "with open('./DATASET/train/truthful.txt') as t, open('./DATASET/train/deceptive.txt') as d:\n",
    "    T_TRAIN = t.read()\n",
    "    D_TRAIN = d.read()\n",
    "    \n",
    "with open('./DATASET/validation/truthful.txt') as t, open('./DATASET/validation/deceptive.txt') as d:\n",
    "    T_VAL = t.read()\n",
    "    D_VAL = d.read()\n",
    "    \n",
    "with open('./DATASET/test/test.txt') as t:\n",
    "    TEST = t.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return add_start_characters(text).split()\n",
    "    \n",
    "def add_start_characters(words):\n",
    "    words = '<s> ' + words\n",
    "    words = words.replace('\\n', ' <s> ')\n",
    "    return words[:-5]\n",
    "\n",
    "def check_for_unk_words(wordlist, tokenlist):\n",
    "    # replace all unknown words with <UNK> token\n",
    "    for i, token in enumerate(wordlist):\n",
    "        if token not in tokenlist:\n",
    "              wordlist[i] = '<UNK>'\n",
    "    return wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unigram_corpus(wordlist):\n",
    "    return dict(Counter(wordlist))\n",
    "\n",
    "def get_unigram_prob(unigram, unigram_corpus):\n",
    "    total_words = 0\n",
    "    for key in unigram_corpus:\n",
    "        total_words += unigram_corpus[key]\n",
    "    # I changed the default value to 1 from 0 to reflect smoothing\n",
    "    return unigram_corpus.get(unigram, 1)/total_words\n",
    "\n",
    "def get_bigram_corpus(wordlist):\n",
    "    corpus = {}\n",
    "    for i, word in enumerate(wordlist[1:], start=1):\n",
    "        if word != '<s>':\n",
    "            if (wordlist[i-1], word) not in corpus:\n",
    "                corpus[(wordlist[i-1], word)] = 1\n",
    "            else:\n",
    "                corpus[(wordlist[i-1], word)] += 1\n",
    "    return corpus\n",
    "\n",
    "# added <UNK> as a token when creating the smooth bigram corpus \n",
    "# not added as token for unigram corpus\n",
    "def get_smooth_bigram_corpus(tokenlist, bigram_corpus):\n",
    "    tokenlist.append('<UNK>')\n",
    "    df = pd.DataFrame(1, index = tokenlist, columns = tokenlist) \n",
    "    for bigram in bigram_corpus:\n",
    "        df.loc[bigram[0], bigram[1]] += bigram_corpus[bigram]\n",
    "    return df\n",
    "\n",
    "def get_smooth_bigram_prob(bigram, smooth_bigram_corpus):\n",
    "    return smooth_bigram_corpus.loc[bigram[0], bigram[1]]/smooth_bigram_corpus.loc[bigram[0]].sum()\n",
    "\n",
    "def get_n_gram_corpus(wordlist, n):\n",
    "    # wordlist is a preprocessed list of words (strings)\n",
    "    n_gram_corpus = {}\n",
    "    for i, word in enumerate(wordlist):\n",
    "        # general case for n > 2\n",
    "        if i + n > len(wordlist) - 1:\n",
    "            break\n",
    "        n_gram = tuple([wordlist[i+x] for x in range(n)])\n",
    "        # special case when n is 1\n",
    "        if n == 1:\n",
    "            # by convention, we now use strings as keys for unigram models and tuples for bigram models\n",
    "            n_gram = word\n",
    "        # special case when n is 2\n",
    "        if n == 2:\n",
    "            if wordlist[i+1] == '<s>':\n",
    "                continue\n",
    "        if n_gram not in n_gram_corpus:\n",
    "            n_gram_corpus[n_gram] = 1\n",
    "        else:\n",
    "            n_gram_corpus[n_gram] += 1 \n",
    "    return n_gram_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramModel():\n",
    "    def __init__(self, *args):\n",
    "        super(NGramModel, self).__init__()\n",
    "    \n",
    "    def get_prob(self, *args):\n",
    "        return\n",
    "    \n",
    "    def get_perp(self, *args):\n",
    "        return\n",
    "        \n",
    "    \n",
    "        \n",
    "class UnigramModel(NGramModel):\n",
    "    # assumes data is preprocessed list of words (strings)   \n",
    "    # with unknown words NOT yet handled !!!\n",
    "    def __init__(self, data):\n",
    "        super(UnigramModel, self).__init__()\n",
    "        self.corpus = get_unigram_corpus(data)\n",
    "\n",
    "    # assumes sequence is preprocessed a list of words (strings)\n",
    "    def get_prob(self, sequence):\n",
    "        product = 1\n",
    "        for word in sequence:\n",
    "            product = product * get_unigram_prob(word, self.corpus)\n",
    "        # added ternary operation for rare case where sequence is empty\n",
    "        return product if sequence != [] else 0\n",
    "    \n",
    "    def get_perp(self, test_corpus):\n",
    "        # assumes test_corpus is a preprocessed list of words (strings)\n",
    "        n_gram_corpus = get_n_gram_corpus(test_corpus, 1)        \n",
    "        N = len(n_gram_corpus)\n",
    "        acc = 0\n",
    "        for n_gram in n_gram_corpus:\n",
    "            acc -= math.log(self.get_prob(n_gram))\n",
    "        return math.e ** ((1/N) * acc)\n",
    "    \n",
    "class SmoothBigramModel(NGramModel):\n",
    "    # assumes data is preprocessed list of words (strings)\n",
    "    # with unknown words NOT yet handled !!!\n",
    "    def __init__(self, data):\n",
    "        super(SmoothBigramModel, self).__init__()\n",
    "        self.tokens = list(get_unigram_corpus(data).keys())\n",
    "        corpus = get_bigram_corpus(data)\n",
    "        self.corpus = get_smooth_bigram_corpus(self.tokens, corpus)\n",
    "\n",
    "    # assumes sequence is a preprocessed list of words (strings)\n",
    "    def get_prob(self, sequence):\n",
    "        bigrams = list(get_bigram_corpus(sequence).keys())\n",
    "        product = 1\n",
    "        for bigram in bigrams:\n",
    "            product = product * get_smooth_bigram_prob(bigram, self.corpus)\n",
    "        # added ternary operation for rare case where sequence is fewer than 2 words\n",
    "        return product if bigrams != [] else 0\n",
    "    \n",
    "    def get_perp(self, test_corpus):\n",
    "        # assumes test_corpus is a preprocessed list of words (strings)\n",
    "        n_gram_corpus = get_n_gram_corpus(test_corpus, 2)   \n",
    "        # length - 1 since we don't compute probability of first words\n",
    "        N = len(n_gram_corpus) - 1\n",
    "        acc = 0\n",
    "        for n_gram in n_gram_corpus:\n",
    "            acc -= math.log(self.get_prob(n_gram))\n",
    "        return math.e ** ((1/N) * acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "truthful_unigram_model = UnigramModel(preprocess(T_TRAIN))\n",
    "deceptive_unigram_model = UnigramModel(preprocess(D_TRAIN))\n",
    "\n",
    "truthful_smooth_bigram_model = SmoothBigramModel(preprocess(T_TRAIN))\n",
    "deceptive_smooth_bigram_model = SmoothBigramModel(preprocess(D_TRAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_VAL_CLEAN = check_for_unk_words(preprocess(T_VAL), truthful_smooth_bigram_model.tokens)\n",
    "D_VAL_CLEAN = check_for_unk_words(preprocess(D_VAL), deceptive_smooth_bigram_model.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125249218788.12532\n",
      "54835933847.04513\n",
      "3543.50724405135\n",
      "2730.1681604013293\n"
     ]
    }
   ],
   "source": [
    "print(truthful_unigram_model.get_perp(T_VAL_CLEAN))\n",
    "# truthful_unigram_model.get_perp(D_VAL_CLEAN)\n",
    "\n",
    "# deceptive_unigram_model.get_perp(T_VAL_CLEAN)\n",
    "print(deceptive_unigram_model.get_perp(D_VAL_CLEAN))\n",
    "\n",
    "print(truthful_smooth_bigram_model.get_perp(T_VAL_CLEAN))\n",
    "# truthful_smooth_bigram_model.get_perp(D_VAL_CLEAN)\n",
    "\n",
    "# deceptive_smooth_bigram_model.get_perp(T_VAL_CLEAN)\n",
    "print(deceptive_smooth_bigram_model.get_perp(D_VAL_CLEAN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
